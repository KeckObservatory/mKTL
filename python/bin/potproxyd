#! /usr/bin/env kpython3

# This is a POT proxy front-end. It should be configuration driven, and be
# willing to invoke as many subprocesses as necessary in order to provide
# POT access to any number of different proxied store components.

import atexit
import itertools
import json
import os
import subprocess
import sys
import tempfile
import threading
import time
import zmq

import POT

zmq_context = zmq.Context()


def main():

    ### This is a quick+dirty approach to running up a KTL/POT proxy. The real
    ### proxy daemon should be driven by a ConfigParser configuration file,
    ### which defines the name of the store, the proxy subprocess call that
    ### should be invoked, and any optional arguments.

    if len(sys.argv) < 2:
        raise ValueError('no service specified on the command line')

    names = sys.argv[1:]

    pub = POT.Protocol.Publish.Server()
    req = RequestServer()

    # PUB and REP messages can flow directly from the subprocess out to the
    # external interface without any additional handling; inbound requests
    # on the external interface have to be parsed to know which subprocess
    # should handle the request.

    # The handling here only allows for unique store names associated with
    # a subprocess/relay; does this need to allow for the possibility of
    # multiple subprocesses associated with a single store name?

    for name in names:
        main.subs[name] = ProxySubprocess(name, req, pub)

    while True:
        try:
            main.shutdown.wait(30)
        except (KeyboardInterrupt, SystemExit):
            break


main.subs = dict()
main.shutdown = threading.Event()



class InternalRequest:

    req_id = itertools.count(0xFFFFFFFF + 1)
    req_id_lock = threading.Lock()

    def __init__(self):
        self.event = threading.Event()

        InternalRequest.req_id_lock.acquire()
        self.req_id = next(InternalRequest.req_id)
        InternalRequest.req_id_lock.release()


    def complete(self, response):
        self.response = response
        self.event.set()


    def wait(self):
        self.event.wait()
        return self.response


# end of class InternalRequest



class ProxySubprocess:

    def __init__(self, name, req_server, pub_server):

        socketdir = tempfile.mkdtemp()
        atexit.register(cleanupSockets, socketdir)

        req_address = os.path.join(socketdir, 'req')
        pub_address = os.path.join(socketdir, 'pub')

        req_address = 'ipc://' + req_address
        pub_address = 'ipc://' + pub_address

        self.config = None
        self.name = name
        self.pub_address = pub_address
        self.req_address = req_address

        self.pub = PublishRelay(pub_address, pub_server)
        self.req = RequestRelay(req_address, req_server)

        # The subprocess should be instantiated last so that the relays are
        # intact and ready to be accessed.

        self.subprocess = None

        self.thread = threading.Thread(target=self.run)
        self.thread.daemon = True
        self.thread.start()


    def run(self):

        self.subprocess = self.startSubprocess()

        while True:
            try:
                exitcode = self.subprocess.wait(30)
            except subprocess.TimeoutExpired:
                continue

            # Process died. Go back to the top of the loop after some artificial
            # delay to give things a chance to recover.

            ### This should log appropriately, and probably check for some sort
            ### of broader indicator that we should no longer be running.

            print('Proxy subprocess died for ' + self.name)
            time.sleep(10)
            self.subprocess = self.startSubprocess()


    def reconfig(self):

        request = dict()
        request['request'] = 'CONFIG'
        request['name'] = self.name

        new_config = self.req.internal_request(request)

        ### Error handling goes here. If there is an error, or there is
        ### no configuration data, log the error, at a minimum.

        self.config = new_config['data']


    def startSubprocess(self):

        arguments = list()
        arguments.append('./potsub')
        arguments.append(self.req_address)
        arguments.append(self.pub_address)
        arguments.append(self.name)

        pipe = subprocess.PIPE
        ##proxysub = subprocess.Popen(arguments, stdout=pipe, stderr=pipe)
        proxysub = subprocess.Popen(arguments)

        self.reconfig()
        return proxysub


# end of class ProxySubprocess


class PublishRelay:

    def __init__(self, internal, external):

        self.external = external

        self.internal = internal
        self.internal_socket = zmq_context.socket(zmq.SUB)
        self.internal_socket.connect(internal)
        self.internal_socket.setsockopt(zmq.SUBSCRIBE, b'')

        # Since there's no additional handling with published messages we can
        # leverage a direct ZeroMQ proxy routine. We still have to encapsulate
        # it in a background thread, as the zmq.proxy() call never returns.

        proxy_args = (self.external.socket, self.internal_socket)
        thread = threading.Thread(target=zmq.proxy, args=proxy_args)
        thread.daemon = True
        thread.start()


# end of class PublishRelay


class RequestRelay:

    def __init__(self, internal, external):

        self.external = external

        self.internal = internal
        self.internal_socket = zmq_context.socket(zmq.DEALER)
        self.internal_socket.bind(internal)

        self.internal_requests = dict()
        self.external_requests = dict()

        self.thread = threading.Thread(target=self.run)
        self.thread.daemon = True
        self.thread.start()


    def external_request(self, ident, request):
        ''' Relay a request from the external interface to our subprocess for
            proper handling.
        '''

        req_id = request['id']
        self.external_requests[req_id] = ident

        request = json.dumps(request)
        request = request.encode()

        self.internal_socket.send(request)


    def internal_request(self, request):
        ''' Issue an internal request to a subprocess, via the subprocess
            request socket.
        '''

        internal = InternalRequest()
        self.internal_requests[internal.req_id] = internal

        request['id'] = internal.req_id
        request = json.dumps(request)
        request = request.encode()
        self.internal_socket.send(request)

        response = internal.wait()
        del self.internal_requests[internal.req_id]

        return response


    def run(self):

        ### This needs to watch for errors and possibly flag that the
        ### subprocess needs to be restarted.

        # Messages outbound from the subprocess should be relayed directly
        # to the external socket.

        poller = zmq.Poller()
        poller.register(self.internal_socket, zmq.POLLIN)

        while True:
            sockets = poller.poll(10000)
            for active, flag in sockets:
                if self.internal_socket == active:
                    response = self.internal_socket.recv()
                    response_dict = json.loads(response)
                    response_id = response_dict['id']

                    ### This assumes the response is JSON. This won't work
                    ### in the bulk data case.

                    if len(self.internal_requests) > 0:
                        try:
                            request = self.internal_requests[response_id]
                        except KeyError:
                            pass
                        else:
                            response_type = response_dict['message']
                            if response_type == 'REP':
                                request.complete(response_dict)
                            continue

                    # If the response is not due to an internal request it
                    # should be a response destined for the external interface.

                    ident = self.external_requests[response_id]

                    ### The removal of the id -> ident mapping would need to be
                    ### more intelligent to handle the bulk data case.

                    if response_dict['message'] != 'ACK':
                        del self.external_requests[response_id]

                    self.external.send(ident, response)


# end of class RequestRelay



class RequestServer(POT.Protocol.Request.Server):

    def req_config(self, ident, request):

        try:
            request_name = request['name']
        except KeyError:
            raise KeyError('CONFIG request must specify a name')

        try:
            sub = main.subs[request_name]
        except KeyError:
            raise KeyError('no local configuration for ' + repr(request_name))

        return sub.config


    def req_handler(self, ident, request):
        ''' Inspect the incoming request type and decide how a response
            will be generated. Interactive requests are handled exclusively
            by the subprocess, including the ACK of the request; other request
            types are handled immediately via subroutines called here.
        '''

        try:
            type = request['request']
        except KeyError:
            self.req_ack(ident, request)
            raise KeyError("invalid request JSON, 'request' not set")

        try:
            name = request['name']
        except KeyError:
            if type != 'HASH':
                self.req_ack(ident, request)
                raise KeyError("invalid request JSON, 'name' not set")

        if type == 'GET' or type == 'SET':
            # The subprocess will ACK these requests, as well as issue
            # appropriate responses once the request is handled; returning
            # None from this routine will indicate no immediate response
            # should be issued.
            self.req_relay(ident, request)
            payload = None
        else:
            self.req_ack(ident, request)
            if type == 'HASH':
                payload = self.req_hash(ident, request)
            elif type == 'CONFIG':
                payload = self.req_config(ident, request)
            else:
                raise ValueError('unhandled request type: ' + type)

        return payload


    def req_hash(self, ident, request):

        try:
            request = request['name']
        except KeyError:
            request = None

        if request is not None:
            try:
                main.subs[request]
            except KeyError:
                raise KeyError('no local configuration for ' + repr(request))

        hashes = list()
        for name in main.subs:
            if request is None or request == name:
                sub = main.subs[name]

                payload = dict()
                payload['name'] = name
                payload['hash'] = sub.config['hash']
                hashes.append(payload)

        return hashes


    def req_relay(self, ident, request):
        ''' Relay the incoming request to the correct subprocess. The
            :class:`RequestRelay` instance associated with that subprocess
            handles the communication in both directions.
        '''

        # The request could be for one of any of the stores associated with
        # this proxy. We have to know the store name to know which subprocess
        # to send it to.

        name = request['name']

        store = name.split('.', 1)[0]

        try:
            sub = main.subs[store]
        except KeyError:
            raise KeyError('no local store for ' + repr(store))

        sub.req.external_request(ident, request)


# end of class RequestServer



def cleanupSockets(socketdir):
    sockets = os.listdir(socketdir)

    for socket in sockets:
        os.remove(os.path.join(socketdir, socket))

    os.rmdir(socketdir)



if __name__ == '__main__':
    main()

# vim: set expandtab tabstop=8 softtabstop=4 shiftwidth=4 autoindent:
